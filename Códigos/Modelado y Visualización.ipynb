{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP y Visualización\n",
    "\n",
    "Input: Datasets Predios, Publicaciones Científicas, Nombre Especies, Países\n",
    "Output: Análisis de tendencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar librerias\n",
    "\n",
    "import json\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "#from spacy import displacy\n",
    "\n",
    "import pandas as pd\n",
    "import plotly_express as px\n",
    "#from spacy.tokens import DocBin\n",
    "from collections import Counter\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, dash_table,callback, Dash\n",
    "\n",
    "from dash.exceptions import PreventUpdate\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import dash_bootstrap_components as dbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar datasets: \n",
    "Predios, Publicaciones Científicas, Nombre Especies y Países"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset predios\n",
    "df_predios=pd.read_excel('..\Archivos\Terrenos.xlsx',sheet_name='Sheet1')\n",
    "\n",
    "#Dataset Publicaciones Científicas\n",
    "with open ('..\Archivos\pubmed_data262.json','r',encoding='utf-8') as f:\n",
    "    pubmed_data=json.load(f)\n",
    "\n",
    "#Dataset Nombre Especies\n",
    "df_especies=pd.read_excel('..\Archivos\Terrenos.xlsx',sheet_name='Hoja1')\n",
    "\n",
    "#Dataset Países\n",
    "codigo_paises=pd.read_excel('..\Archivos\Copia de código paises.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar GeoJSON\n",
    "with open(\"..\Archivos\terrenos_enriquecido_ID.geojson\", \"r\", encoding=\"utf-8\") as f:\n",
    "    geojson_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_predios=pd.merge(df_predios,df_especies[['ID_ESP1','ID','Nombre científico']])\n",
    "df_predios_group=df_predios.groupby(['USO_CEFOR','Nombre científico','ID'])['SUP_HA'].sum().reset_index()\n",
    "df_predios_group_lplp=df_predios.groupby(['NOMBRE','Nombre científico','ID'])['SUP_HA'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_imagen=Image.open('..\Archivos\Logo_udec_maci.png')\n",
    ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wordcloud\n",
    "\n",
    "def procesar_keywords (keywords):\n",
    "\n",
    "    kw=[]\n",
    "    for keyword in keywords:\n",
    "        for key in keyword:\n",
    "            kw.append(key)\n",
    "\n",
    "    keywords_string=' ,'.join(e for e in kw)\n",
    "    return keywords_string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NPL y Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('limites_unificados.geojson', \"r\", encoding=\"utf-8\") as f:\n",
    "    geojson_limite = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8053/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x11ac3c8b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "ValueError                                Traceback (most recent call last)\n",
      "File ~/Library/CloudStorage/OneDrive-DataConnect/mac/.venv/lib/python3.9/site-packages/_plotly_utils/basevalidators.py:767, in NumberValidator.validate_coerce(\n",
      "    self=<plotly.validators.scatter.marker._size.SizeValidator object>,\n",
      "    v=┌──────────────────────────────────────┐\n",
      "|      ...object)|\n",
      "└──────────────────────────────────────┘\n",
      ")\n",
      "    766 try:\n",
      "--> 767     v_array = copy_to_readonly_numpy_array(v, force_numeric=True)\n",
      "        v = ┌──────────────────────────────────────┐\n",
      "|           Narwhals Series            |\n",
      "|--------------------------------------|\n",
      "|Series([], Name: total, dtype: object)|\n",
      "└──────────────────────────────────────┘\n",
      "    768 except (ValueError, TypeError, OverflowError):\n",
      "\n",
      "File ~/Library/CloudStorage/OneDrive-DataConnect/mac/.venv/lib/python3.9/site-packages/_plotly_utils/basevalidators.py:148, in copy_to_readonly_numpy_array(\n",
      "    v=array([], dtype=object),\n",
      "    kind=(),\n",
      "    force_numeric=True\n",
      ")\n",
      "    147 if force_numeric and new_v.dtype.kind not in numeric_kinds:\n",
      "--> 148     raise ValueError(\n",
      "    149         \"Input value is not numeric and force_numeric parameter set to True\"\n",
      "    150     )\n",
      "    152 if \"U\" not in kind:\n",
      "    153     # Force non-numeric arrays to have object type\n",
      "    154     # --------------------------------------------\n",
      "   (...)\n",
      "    157     # numpy converts the integers to strings and returns array of dtype\n",
      "    158     # '<U21'\n",
      "\n",
      "ValueError: Input value is not numeric and force_numeric parameter set to True\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[39], line 211, in filtro(valor=[])\n",
      "    209 #esta parte filtra el json: abstract\n",
      "    210 json_filtrado = [{paper['PMID']: paper['Abstract']} for paper in pubmed_data if paper['ID'] in valor]\n",
      "--> 211 fig=px.scatter(procesar_json_fil(json_filtrado),x='f rel',y='f abs',size='total',hover_data=['listas presentes'],hover_name='lemma',opacity=0.5,title=\"Presencia y Abundancia de términos\",labels={'f rel':'Presencia','f abs':'Abundancia'})\n",
      "        json_filtrado = []\n",
      "        px = <module 'plotly_express' from '/Users/eduardosolizpaillahueque/Library/CloudStorage/OneDrive-DataConnect/mac/.venv/lib/python3.9/site-packages/plotly_express/__init__.py'>\n",
      "    213 #esta parte filtra el json: solo pmids:lista\n",
      "    214 lista_pmids=[]\n",
      "\n",
      "File ~/Library/CloudStorage/OneDrive-DataConnect/mac/.venv/lib/python3.9/site-packages/plotly/express/_chart_types.py:69, in scatter(\n",
      "    data_frame=Empty DataFrame\n",
      "Columns: [lemma, listas presentes, f abs, cantidad listas, f rel, total]\n",
      "Index: [],\n",
      "    x='f rel',\n",
      "    y='f abs',\n",
      "    color=None,\n",
      "    symbol=None,\n",
      "    size='total',\n",
      "    hover_name='lemma',\n",
      "    hover_data=['listas presentes'],\n",
      "    custom_data=None,\n",
      "    text=None,\n",
      "    facet_row=None,\n",
      "    facet_col=None,\n",
      "    facet_col_wrap=0,\n",
      "    facet_row_spacing=None,\n",
      "    facet_col_spacing=None,\n",
      "    error_x=None,\n",
      "    error_x_minus=None,\n",
      "    error_y=None,\n",
      "    error_y_minus=None,\n",
      "    animation_frame=None,\n",
      "    animation_group=None,\n",
      "    category_orders=None,\n",
      "    labels={'f abs': 'Abundancia', 'f rel': 'Presencia'},\n",
      "    orientation=None,\n",
      "    color_discrete_sequence=None,\n",
      "    color_discrete_map=None,\n",
      "    color_continuous_scale=None,\n",
      "    range_color=None,\n",
      "    color_continuous_midpoint=None,\n",
      "    symbol_sequence=None,\n",
      "    symbol_map=None,\n",
      "    opacity=0.5,\n",
      "    size_max=None,\n",
      "    marginal_x=None,\n",
      "    marginal_y=None,\n",
      "    trendline=None,\n",
      "    trendline_options=None,\n",
      "    trendline_color_override=None,\n",
      "    trendline_scope='trace',\n",
      "    log_x=False,\n",
      "    log_y=False,\n",
      "    range_x=None,\n",
      "    range_y=None,\n",
      "    render_mode='auto',\n",
      "    title='Presencia y Abundancia de términos',\n",
      "    subtitle=None,\n",
      "    template=None,\n",
      "    width=None,\n",
      "    height=None\n",
      ")\n",
      "     14 def scatter(\n",
      "     15     data_frame=None,\n",
      "     16     x=None,\n",
      "   (...)\n",
      "     63     height=None,\n",
      "     64 ) -> go.Figure:\n",
      "     65     \"\"\"\n",
      "     66     In a scatter plot, each row of `data_frame` is represented by a symbol\n",
      "     67     mark in 2D space.\n",
      "     68     \"\"\"\n",
      "---> 69     return make_figure(args=locals(), constructor=go.Scatter)\n",
      "        go = <module 'plotly.graph_objs' from '/Users/eduardosolizpaillahueque/Library/CloudStorage/OneDrive-DataConnect/mac/.venv/lib/python3.9/site-packages/plotly/graph_objs/__init__.py'>\n",
      "\n",
      "File ~/Library/CloudStorage/OneDrive-DataConnect/mac/.venv/lib/python3.9/site-packages/plotly/express/_core.py:2671, in make_figure(\n",
      "    args={'animation_frame': None, 'animation_group': None, 'category_orders': None, 'color': None, 'color_continuous_midpoint': None, 'color_continuous_scale': None, 'color_discrete_map': None, 'color_discrete_sequence': None, 'custom_data': None, 'data_frame': Empty DataFrame\n",
      "Columns: [lemma, listas presentes, f abs, cantidad listas, f rel, total]\n",
      "Index: [], ...},\n",
      "    constructor=<class 'plotly.graph_objs._scatter.Scatter'>,\n",
      "    trace_patch={'marker': {'opacity': 0.5, 'size': ┌──────────────────────────────────────┐\n",
      "|      ...object)|\n",
      "└──────────────────────────────────────┘, 'sizemode': 'area', 'sizeref': nan}, 'mode': 'markers', 'orientation': 'v'},\n",
      "    layout_patch={}\n",
      ")\n",
      "   2666         group = group.with_columns((nw.col(var) / group_sum) * 100.0)\n",
      "   2668 patch, fit_results = make_trace_kwargs(\n",
      "   2669     args, trace_spec, group, mapping_labels.copy(), sizeref\n",
      "   2670 )\n",
      "-> 2671 trace.update(patch)\n",
      "        trace = Scatter({\n",
      "    'legendgroup': '',\n",
      "    'marker': {'color': '#636efa', 'opacity': 0.5, 'symbol': 'circle'},\n",
      "    'name': '',\n",
      "    'orientation': 'v',\n",
      "    'showlegend': False\n",
      "})\n",
      "        patch = {'orientation': 'v', 'marker': {'opacity': 0.5, 'size': ┌──────────────────────────────────────┐\n",
      "|           Narwhals Series            |\n",
      "|--------------------------------------|\n",
      "|Series([], Name: total, dtype: object)|\n",
      "└──────────────────────────────────────┘, 'sizemode': 'area', 'sizeref': nan}, 'mode': 'markers', 'x': ┌──────────────────────────────────────┐\n",
      "|           Narwhals Series            |\n",
      "|--------------------------------------|\n",
      "|Series([], Name: f rel, dtype: object)|\n",
      "└──────────────────────────────────────┘, 'y': ┌──────────────────────────────────────┐\n",
      "|           Narwhals Series            |\n",
      "|--------------------------------------|\n",
      "|Series([], Name: f abs, dtype: object)|\n",
      "└──────────────────────────────────────┘, 'hovertext': ┌──────────────────────────────────────┐\n",
      "|           Narwhals Series            |\n",
      "|--------------------------------------|\n",
      "|Series([], Name: lemma, dtype: object)|\n",
      "└──────────────────────────────────────┘, 'customdata': ┌───────────────────────────┐\n",
      "|    Narwhals DataFrame     |\n",
      "|---------------------------|\n",
      "|Empty DataFrame            |\n",
      "|Columns: [listas presentes]|\n",
      "|Index: []                  |\n",
      "└───────────────────────────┘, 'hovertemplate': '<b>%{hovertext}</b><br><br>Presencia=%{x}<br>Abundancia=%{y}<br>total=%{marker.size}<br>listas presentes=%{customdata[0]}<extra></extra>'}\n",
      "   2672 if fit_results is not None:\n",
      "   2673     trendline_rows.append(mapping_labels.copy())\n",
      "\n",
      "File ~/Library/CloudStorage/OneDrive-DataConnect/mac/.venv/lib/python3.9/site-packages/plotly/basedatatypes.py:5125, in BasePlotlyType.update(\n",
      "    self=Scatter({\n",
      "    'legendgroup': '',\n",
      "    'marker': {...   'orientation': 'v',\n",
      "    'showlegend': False\n",
      "}),\n",
      "    dict1={'customdata': ┌───────────────────────────┐\n",
      "|    Narwhals Data...                  |\n",
      "└───────────────────────────┘, 'hovertemplate': '<b>%{hovertext}</b><br><br>Presencia=%{x}<br>Abu...>listas presentes=%{customdata[0]}<extra></extra>', 'hovertext': ┌──────────────────────────────────────┐\n",
      "|      ...object)|\n",
      "└──────────────────────────────────────┘, 'marker': {'opacity': 0.5, 'size': ┌──────────────────────────────────────┐\n",
      "|      ...object)|\n",
      "└──────────────────────────────────────┘, 'sizemode': 'area', 'sizeref': nan}, 'mode': 'markers', 'orientation': 'v', 'x': ┌──────────────────────────────────────┐\n",
      "|      ...object)|\n",
      "└──────────────────────────────────────┘, 'y': ┌──────────────────────────────────────┐\n",
      "|      ...object)|\n",
      "└──────────────────────────────────────┘},\n",
      "    overwrite=False,\n",
      "    **kwargs={}\n",
      ")\n",
      "   5123         BaseFigure._perform_update(self, kwargs, overwrite=overwrite)\n",
      "   5124 else:\n",
      "-> 5125     BaseFigure._perform_update(self, dict1, overwrite=overwrite)\n",
      "        self = Scatter({\n",
      "    'legendgroup': '',\n",
      "    'marker': {'color': '#636efa', 'opacity': 0.5, 'symbol': 'circle'},\n",
      "    'name': '',\n",
      "    'orientation': 'v',\n",
      "    'showlegend': False\n",
      "})\n",
      "        dict1 = {'orientation': 'v', 'marker': {'opacity': 0.5, 'size': ┌──────────────────────────────────────┐\n",
      "|           Narwhals Series            |\n",
      "|--------------------------------------|\n",
      "|Series([], Name: total, dtype: object)|\n",
      "└──────────────────────────────────────┘, 'sizemode': 'area', 'sizeref': nan}, 'mode': 'markers', 'x': ┌──────────────────────────────────────┐\n",
      "|           Narwhals Series            |\n",
      "|--------------------------------------|\n",
      "|Series([], Name: f rel, dtype: object)|\n",
      "└──────────────────────────────────────┘, 'y': ┌──────────────────────────────────────┐\n",
      "|           Narwhals Series            |\n",
      "|--------------------------------------|\n",
      "|Series([], Name: f abs, dtype: object)|\n",
      "└──────────────────────────────────────┘, 'hovertext': ┌──────────────────────────────────────┐\n",
      "|           Narwhals Series            |\n",
      "|--------------------------------------|\n",
      "|Series([], Name: lemma, dtype: object)|\n",
      "└──────────────────────────────────────┘, 'customdata': ┌───────────────────────────┐\n",
      "|    Narwhals DataFrame     |\n",
      "|---------------------------|\n",
      "|Empty DataFrame            |\n",
      "|Columns: [listas presentes]|\n",
      "|Index: []                  |\n",
      "└───────────────────────────┘, 'hovertemplate': '<b>%{hovertext}</b><br><br>Presencia=%{x}<br>Abundancia=%{y}<br>total=%{marker.size}<br>listas presentes=%{customdata[0]}<extra></extra>'}\n",
      "        overwrite = False\n",
      "   5126     BaseFigure._perform_update(self, kwargs, overwrite=overwrite)\n",
      "   5128 return self\n",
      "\n",
      "File ~/Library/CloudStorage/OneDrive-DataConnect/mac/.venv/lib/python3.9/site-packages/plotly/basedatatypes.py:3905, in BaseFigure._perform_update(\n",
      "    plotly_obj=Scatter({\n",
      "    'legendgroup': '',\n",
      "    'marker': {...   'orientation': 'v',\n",
      "    'showlegend': False\n",
      "}),\n",
      "    update_obj={'customdata': ┌───────────────────────────┐\n",
      "|    Narwhals Data...                  |\n",
      "└───────────────────────────┘, 'hovertemplate': '<b>%{hovertext}</b><br><br>Presencia=%{x}<br>Abu...>listas presentes=%{customdata[0]}<extra></extra>', 'hovertext': ┌──────────────────────────────────────┐\n",
      "|      ...object)|\n",
      "└──────────────────────────────────────┘, 'marker': {'opacity': 0.5, 'size': ┌──────────────────────────────────────┐\n",
      "|      ...object)|\n",
      "└──────────────────────────────────────┘, 'sizemode': 'area', 'sizeref': nan}, 'mode': 'markers', 'orientation': 'v', 'x': ┌──────────────────────────────────────┐\n",
      "|      ...object)|\n",
      "└──────────────────────────────────────┘, 'y': ┌──────────────────────────────────────┐\n",
      "|      ...object)|\n",
      "└──────────────────────────────────────┘},\n",
      "    overwrite=False\n",
      ")\n",
      "   3899 validator = plotly_obj._get_prop_validator(key)\n",
      "   3901 if isinstance(validator, CompoundValidator) and isinstance(val, dict):\n",
      "   3902 \n",
      "   3903     # Update compound objects recursively\n",
      "   3904     # plotly_obj[key].update(val)\n",
      "-> 3905     BaseFigure._perform_update(plotly_obj[key], val)\n",
      "        plotly_obj = Scatter({\n",
      "    'legendgroup': '',\n",
      "    'marker': {'color': '#636efa', 'opacity': 0.5, 'symbol': 'circle'},\n",
      "    'name': '',\n",
      "    'orientation': 'v',\n",
      "    'showlegend': False\n",
      "})\n",
      "        key = 'marker'\n",
      "        val = {'opacity': 0.5, 'size': ┌──────────────────────────────────────┐\n",
      "|           Narwhals Series            |\n",
      "|--------------------------------------|\n",
      "|Series([], Name: total, dtype: object)|\n",
      "└──────────────────────────────────────┘, 'sizemode': 'area', 'sizeref': nan}\n",
      "   3906 elif isinstance(validator, CompoundArrayValidator):\n",
      "   3907     if plotly_obj[key]:\n",
      "   3908         # plotly_obj has an existing non-empty array for key\n",
      "   3909         # In this case we merge val into the existing elements\n",
      "\n",
      "File ~/Library/CloudStorage/OneDrive-DataConnect/mac/.venv/lib/python3.9/site-packages/plotly/basedatatypes.py:3926, in BaseFigure._perform_update(\n",
      "    plotly_obj=scatter.Marker({\n",
      "    'color': '#636efa', 'opacity': 0.5, 'symbol': 'circle'\n",
      "}),\n",
      "    update_obj={'opacity': 0.5, 'size': ┌──────────────────────────────────────┐\n",
      "|      ...object)|\n",
      "└──────────────────────────────────────┘, 'sizemode': 'area', 'sizeref': nan},\n",
      "    overwrite=False\n",
      ")\n",
      "   3923                 plotly_obj[key] = val\n",
      "   3924         else:\n",
      "   3925             # Assign non-compound value\n",
      "-> 3926             plotly_obj[key] = val\n",
      "        plotly_obj = scatter.Marker({\n",
      "    'color': '#636efa', 'opacity': 0.5, 'symbol': 'circle'\n",
      "})\n",
      "        key = 'size'\n",
      "        val = ┌──────────────────────────────────────┐\n",
      "|           Narwhals Series            |\n",
      "|--------------------------------------|\n",
      "|Series([], Name: total, dtype: object)|\n",
      "└──────────────────────────────────────┘\n",
      "   3928 elif isinstance(plotly_obj, tuple):\n",
      "   3930     if len(update_obj) == 0:\n",
      "   3931         # Nothing to do\n",
      "\n",
      "File ~/Library/CloudStorage/OneDrive-DataConnect/mac/.venv/lib/python3.9/site-packages/plotly/basedatatypes.py:4860, in BasePlotlyType.__setitem__(\n",
      "    self=scatter.Marker({\n",
      "    'color': '#636efa', 'opacity': 0.5, 'symbol': 'circle'\n",
      "}),\n",
      "    prop='size',\n",
      "    value=┌──────────────────────────────────────┐\n",
      "|      ...object)|\n",
      "└──────────────────────────────────────┘\n",
      ")\n",
      "   4856         self._set_array_prop(prop, value)\n",
      "   4858     # ### Handle simple property ###\n",
      "   4859     else:\n",
      "-> 4860         self._set_prop(prop, value)\n",
      "        prop = 'size'\n",
      "        self = scatter.Marker({\n",
      "    'color': '#636efa', 'opacity': 0.5, 'symbol': 'circle'\n",
      "})\n",
      "        value = ┌──────────────────────────────────────┐\n",
      "|           Narwhals Series            |\n",
      "|--------------------------------------|\n",
      "|Series([], Name: total, dtype: object)|\n",
      "└──────────────────────────────────────┘\n",
      "   4861 else:\n",
      "   4862     # Make sure properties dict is initialized\n",
      "   4863     self._init_props()\n",
      "\n",
      "File ~/Library/CloudStorage/OneDrive-DataConnect/mac/.venv/lib/python3.9/site-packages/plotly/basedatatypes.py:5204, in BasePlotlyType._set_prop(\n",
      "    self=scatter.Marker({\n",
      "    'color': '#636efa', 'opacity': 0.5, 'symbol': 'circle'\n",
      "}),\n",
      "    prop='size',\n",
      "    val=┌──────────────────────────────────────┐\n",
      "|      ...object)|\n",
      "└──────────────────────────────────────┘\n",
      ")\n",
      "   5202         return\n",
      "   5203     else:\n",
      "-> 5204         raise err\n",
      "   5206 # val is None\n",
      "   5207 # -----------\n",
      "   5208 if val is None:\n",
      "   5209     # Check if we should send null update\n",
      "\n",
      "File ~/Library/CloudStorage/OneDrive-DataConnect/mac/.venv/lib/python3.9/site-packages/plotly/basedatatypes.py:5199, in BasePlotlyType._set_prop(\n",
      "    self=scatter.Marker({\n",
      "    'color': '#636efa', 'opacity': 0.5, 'symbol': 'circle'\n",
      "}),\n",
      "    prop='size',\n",
      "    val=┌──────────────────────────────────────┐\n",
      "|      ...object)|\n",
      "└──────────────────────────────────────┘\n",
      ")\n",
      "   5196 validator = self._get_validator(prop)\n",
      "   5198 try:\n",
      "-> 5199     val = validator.validate_coerce(val)\n",
      "        validator = <plotly.validators.scatter.marker._size.SizeValidator object at 0x11b983610>\n",
      "        val = ┌──────────────────────────────────────┐\n",
      "|           Narwhals Series            |\n",
      "|--------------------------------------|\n",
      "|Series([], Name: total, dtype: object)|\n",
      "└──────────────────────────────────────┘\n",
      "   5200 except ValueError as err:\n",
      "   5201     if self._skip_invalid:\n",
      "\n",
      "File ~/Library/CloudStorage/OneDrive-DataConnect/mac/.venv/lib/python3.9/site-packages/_plotly_utils/basevalidators.py:769, in NumberValidator.validate_coerce(\n",
      "    self=<plotly.validators.scatter.marker._size.SizeValidator object>,\n",
      "    v=┌──────────────────────────────────────┐\n",
      "|      ...object)|\n",
      "└──────────────────────────────────────┘\n",
      ")\n",
      "    767     v_array = copy_to_readonly_numpy_array(v, force_numeric=True)\n",
      "    768 except (ValueError, TypeError, OverflowError):\n",
      "--> 769     self.raise_invalid_val(v)\n",
      "        v = ┌──────────────────────────────────────┐\n",
      "|           Narwhals Series            |\n",
      "|--------------------------------------|\n",
      "|Series([], Name: total, dtype: object)|\n",
      "└──────────────────────────────────────┘\n",
      "        self = <plotly.validators.scatter.marker._size.SizeValidator object at 0x11b983610>\n",
      "    771 # Check min/max\n",
      "    772 if self.has_min_max:\n",
      "\n",
      "File ~/Library/CloudStorage/OneDrive-DataConnect/mac/.venv/lib/python3.9/site-packages/_plotly_utils/basevalidators.py:299, in BaseValidator.raise_invalid_val(\n",
      "    self=<plotly.validators.scatter.marker._size.SizeValidator object>,\n",
      "    v=┌──────────────────────────────────────┐\n",
      "|      ...object)|\n",
      "└──────────────────────────────────────┘,\n",
      "    inds=None\n",
      ")\n",
      "    296             for i in inds:\n",
      "    297                 name += \"[\" + str(i) + \"]\"\n",
      "--> 299         raise ValueError(\n",
      "        name = 'size'\n",
      "        self = <plotly.validators.scatter.marker._size.SizeValidator object at 0x11b983610>\n",
      "        self.parent_name = 'scatter.marker'\n",
      "        v = ┌──────────────────────────────────────┐\n",
      "|           Narwhals Series            |\n",
      "|--------------------------------------|\n",
      "|Series([], Name: total, dtype: object)|\n",
      "└──────────────────────────────────────┘\n",
      "    300             \"\"\"\n",
      "    301     Invalid value of type {typ} received for the '{name}' property of {pname}\n",
      "    302         Received value: {v}\n",
      "    303 \n",
      "    304 {valid_clr_desc}\"\"\".format(\n",
      "    305                 name=name,\n",
      "    306                 pname=self.parent_name,\n",
      "    307                 typ=type_str(v),\n",
      "    308                 v=repr(v),\n",
      "    309                 valid_clr_desc=self.description(),\n",
      "    310             )\n",
      "    311         )\n",
      "\n",
      "ValueError: \n",
      "    Invalid value of type 'narwhals.stable.v1.Series' received for the 'size' property of scatter.marker\n",
      "        Received value: ┌──────────────────────────────────────┐\n",
      "|           Narwhals Series            |\n",
      "|--------------------------------------|\n",
      "|Series([], Name: total, dtype: object)|\n",
      "└──────────────────────────────────────┘\n",
      "\n",
      "    The 'size' property is a number and may be specified as:\n",
      "      - An int or float in the interval [0, inf]\n",
      "      - A tuple, list, or one-dimensional numpy array of the above\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "OSError                                   Traceback (most recent call last)\n",
      "OSError: broken data stream when reading image file\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "OSError                                   Traceback (most recent call last)\n",
      "OSError: broken data stream when reading image file\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "OSError                                   Traceback (most recent call last)\n",
      "OSError: broken data stream when reading image file\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "OSError                                   Traceback (most recent call last)\n",
      "OSError: broken data stream when reading image file\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "OSError                                   Traceback (most recent call last)\n",
      "OSError: broken data stream when reading image file\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "OSError                                   Traceback (most recent call last)\n",
      "OSError: broken data stream when reading image file\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "OSError                                   Traceback (most recent call last)\n",
      "OSError: broken data stream when reading image file\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "OSError                                   Traceback (most recent call last)\n",
      "OSError: broken data stream when reading image file\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "OSError                                   Traceback (most recent call last)\n",
      "OSError: broken data stream when reading image file\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "OSError                                   Traceback (most recent call last)\n",
      "OSError: broken data stream when reading image file\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "OSError                                   Traceback (most recent call last)\n",
      "OSError: broken data stream when reading image file\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "OSError                                   Traceback (most recent call last)\n",
      "OSError: broken data stream when reading image file\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "OSError                                   Traceback (most recent call last)\n",
      "OSError: broken data stream when reading image file\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "OSError                                   Traceback (most recent call last)\n",
      "OSError: broken data stream when reading image file\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "OSError                                   Traceback (most recent call last)\n",
      "OSError: broken data stream when reading image file\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "OSError                                   Traceback (most recent call last)\n",
      "OSError: broken data stream when reading image file\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "OSError                                   Traceback (most recent call last)\n",
      "OSError: broken data stream when reading image file\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "OSError                                   Traceback (most recent call last)\n",
      "OSError: broken data stream when reading image file\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "OSError                                   Traceback (most recent call last)\n",
      "OSError: broken data stream when reading image file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#probando esto\n",
    "\n",
    "app=dash.Dash()\n",
    "\n",
    "#funciones globales:\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")     #cargo el modelo\n",
    "\n",
    "options_dict=dict(zip(df_especies['Nombre científico'],df_especies['ID']))     #defino las opciones del menú desplegable\n",
    "\n",
    "def clean_text(texto):                                                         #defino la función de limpieza del texto\n",
    "    return re.sub(r\"<.*?>|[%()=/-]|\\d\", \"\", str(texto)) #nueva versión\n",
    "    #return re.sub(\"<.*?>|%|\\(|\\)|=|-/n|/>-|\\d\", \"\", str(texto))\n",
    "\n",
    "def procesar_json_fil(diccionario):                                         #esta es la función de procesamiento principal\n",
    "    lista=[]\n",
    "    data={}\n",
    "\n",
    "    for entry in diccionario:#lista-dicc. accedo al primer elemento\n",
    "        \n",
    "        for doc_id , text in entry.items():\n",
    "            doc = nlp(clean_text(text))                                      #llamo a la función de limpieza\n",
    "            data_id=[]\n",
    "            for token in doc:\n",
    "                if token.pos_ in [\"NOUN\",\"PROPN\"] and len(token.lemma_)>3 and not token.is_stop:\n",
    "                    \n",
    "                    data_id.append(token.lemma_.lower())\n",
    "                data[doc_id]=data_id\n",
    "    lista.append(data)                                                      #parece que esta parte está un poco demás\n",
    "  \n",
    "    #lista de todas las claves\n",
    "    M=[]\n",
    "    for x,y in data.items():\n",
    "        for e in y:\n",
    "            M.append(e)\n",
    "    L=list(set(M))\n",
    "    #procesamiento de frecuencias\n",
    "    filas=[]\n",
    "    pal_tot=len(M)\n",
    "    lis_tot=len(diccionario)\n",
    "\n",
    "    for e in L:\n",
    "        total=0\n",
    "        listas_presentes=[]\n",
    "\n",
    "        for x,y in data.items():\n",
    "            count = y.count(e)\n",
    "            total += count\n",
    "            if count>0:\n",
    "                listas_presentes.append(x)\n",
    "\n",
    "        filas.append([e,listas_presentes,total/pal_tot*100,len(listas_presentes),len(listas_presentes)/lis_tot*100,total])\n",
    "        \n",
    "    df_res_res=pd.DataFrame(filas,columns=[\"lemma\",\"listas presentes\",\"f abs\",\"cantidad listas\",\"f rel\",\"total\"])\n",
    "    return df_res_res\n",
    "\n",
    "#Procesar json: obtener países\n",
    "\n",
    "#probar generando una lista de dicc\n",
    "\n",
    "def procesar_paises (valor):\n",
    "\n",
    "    #valor=[31,18,25]\n",
    "    lista_pmids=[]\n",
    "\n",
    "    for paper in pubmed_data:\n",
    "        if paper['ID'] in valor:\n",
    "            lista_pmids.append(paper['PMID'])\n",
    "\n",
    "    #aff=[]\n",
    "    #pm=[]\n",
    "    A={}\n",
    "    D=[]\n",
    "    #Lista=[]\n",
    "    for record in pubmed_data:\n",
    "        if record['PMID'] in lista_pmids:\n",
    "                    \n",
    "            for autor in record['Authors']:\n",
    "                affi=autor['Affiliations']\n",
    "                for inst in affi:\n",
    "                \n",
    "                    pm2=\"\".join(record['PMID'])\n",
    "                    aff2=\"\".join(inst)\n",
    "                    A[pm2]=aff2\n",
    "                    D.append(A)\n",
    "\n",
    "\n",
    "    #lista=[]\n",
    "    data=[]\n",
    "\n",
    "    for entry in D:\n",
    "        for doc_id, text in entry.items():\n",
    "\n",
    "            doc=nlp(clean_text(text))\n",
    "            paises=[ent.text for ent in doc.ents if ent.label_ ==\"GPE\"]\n",
    "            for pais in set(paises):\n",
    "                    data.append({\"PMID\":doc_id,\"GPE\":pais})\n",
    "\n",
    "    df_p=pd.DataFrame(data)\n",
    "\n",
    "    #df_p[\"PMID\"] = pd.to_numeric(df_p[\"PMID\"],errors=\"coerce\")\n",
    "    df_p_unique=df_p.drop_duplicates(subset=[\"PMID\",\"GPE\"])\n",
    "\n",
    "    df_unique_conteo=df_p_unique['GPE'].value_counts().reset_index()\n",
    "    df_unique_conteo.columns=['País','Recuento']\n",
    "    df_unique_conteo_codigo=pd.merge(df_unique_conteo,codigo_paises,left_on=\"País\",right_on=\"Country\")\n",
    "\n",
    "    return df_unique_conteo_codigo\n",
    "\n",
    "\n",
    "\n",
    "#Inicio app\n",
    "\n",
    "app=Dash(__name__,external_stylesheets=[dbc.themes.LUX,dbc.icons.FONT_AWESOME])\n",
    "\n",
    "app.layout=dbc.Container([\n",
    "    html.Br(),\n",
    "    dbc.Row([dbc.Col([html.Img(src=ruta_imagen,style={'height':'40px','width':'10%'})])]),\n",
    "    html.Br(),\n",
    "    html.H4(\"Tesina Beatriz Ugalde - 2025\"),\n",
    "    html.Br(),\n",
    "    html.Br(),\n",
    "    html.H1(\"Identificar líneas de trabajo para Potenciar Investigación y Docencia en predios forestales\",style={'text-align':'center','margin-top':'20px'}),\n",
    "    html.Br(),\n",
    "    html.Br(),\n",
    "    html.Br(),\n",
    "    html.P(\"Se busca potenciar la investigación y docencia en predios forestales. \"\n",
    "\n",
    "\"Se muestra la caracterización de dos predios en términos de composición y  uso de suelo. \" \n",
    "\n",
    "\"Se realiza una búsqueda de publicaciones científicas relacionadas con las especies que los habitan, se extraen términos relevantes y se analiza su importancia en función de su presencia y abundancia, promoviendo la búsqueda de tendencias innovadoras en investigación científica.\",style={'text-align':'justify'}),\n",
    "    html.Br(),\n",
    "    html.Br(),\n",
    "    html.H4(\"Caracterización predios forestales\"),\n",
    "    html.Br(),\n",
    "    html.P(\"El centro forestal (CEFOR) perteneciente a la Universidad Austral de Chile, cuenta con un patrimonio de más de 4000 hectáreas de predios forestales, donde se realizan labores de docencia, investigación y extensión. Dos de los predios más antiguos, “Los Pinos“ y “Las Palmas“ cuentan con cerca de 1500 hectáreas de terreno, \"\n",
    "    \"están ubicados a 5 Km del Campus Isla Teja, y presentan gran valor biológico. \"  \n",
    "    \" Seleccione una o más especies para conocer su ubicación, uso y potenciales líneas de investigación\", style={'text-align':'justify'}),\n",
    "    #html.H6(\"Seleccione una o más especies\"),\n",
    "    html.Br(),\n",
    "    html.Div([ dcc.Dropdown(options=[{'label':NOM,'value':ID} for NOM,ID in sorted(options_dict.items(),key=lambda x: x[1], reverse=True)],id=\"entrada\",multi=True)]),\n",
    "    #html.Div([dcc.Input(),dcc.Input(style={'margin_left':'15px'})]),\n",
    "    html.Br(),\n",
    "    html.H6(\"Descripción de las especies seleccionadas\"),\n",
    "    html.Br(),\n",
    "    dbc.Row([dbc.Col([dash_table.DataTable(id='tabla_nombres',style_cell={'textAlign':'left'})]),dbc.Col([dcc.Graph(id='mapa-terrenos', style={\"height\": \"80vh\"})])]),\n",
    "    html.Br(),\n",
    "    html.Br(),\n",
    "    #html.Div([dcc.Graph(id='mapa-terrenos', style={\"height\": \"80vh\"})]),\n",
    "    #html.H6(\"Relación de las especies con los predios\"),\n",
    "    dbc.Row([\n",
    "        dbc.Col([dcc.Graph(id='predios_barras',style={'height':'400px','width':'100%'})]),dbc.Col([dcc.Graph(id='predios_barras_lplp',style={'height':'400px','width':'100%'})])]),\n",
    "    html.Br(),\n",
    "    html.Br(),\n",
    "    html.H4(\"Extracción de términos desde publicaciones científicas\"),\n",
    "    html.Br(),\n",
    "    html.P(\"A partir de las especies seleccionadas en la parte superior, Se obtienen publicaciones científicas desde pubmed central si la especie aparece en el título o abstract.\" \n",
    "\"Se muestra una nube de palabras que agrupa todas las “keywords“ de las publicaciones seleccionadas,  la evolución de las publicaciones en el tiempo y los países donde se investigan dichas especies.\"),\n",
    "    html.Br(),\n",
    "            \n",
    "    dbc.Row([\n",
    "        dbc.Col([html.Img(id='wordcloud',style={'height':'100%','width':'95%'})]),\n",
    "        dbc.Col([dcc.Graph(id='paper_año',style={'height':'100%','width':'95%'})]),\n",
    "        dbc.Col([dcc.Graph(id='mapa_paises',style={'height':'100%','width':'95%'})])],style={'height':'400px'}),\n",
    "    html.Br(),\n",
    "    html.Br(),    \n",
    "    html.P(\"A continuación se realiza un análisis semántico de los abstracts y se extraen términos importantes  y se analizan en función de su presencia y abundancia. La presencia se determina evaluando en cuántas publicaciones diferentes aparece cada término, y la abundancia cuántas veces aparece en total. Así, un término altamente presente y abundante se espera que sea de poca importancia, ya que es transversal a todas las publicaciones, ahora bien un término poco presente podría representar una línea de trabajo innovadora.\"),\n",
    "\n",
    "    dcc.Graph(id='grafico'),\n",
    "    html.Br(),\n",
    "    html.H6(\"Información relacionada al término seleccionado:\"),\n",
    "    html.Br(),\n",
    "    dbc.Row([dbc.Col([dash_table.DataTable(id='tabla',style_cell={'textAlign':'left'},style_data={'whiteSpace':'normal','width':'100px','maxWidth':'100px','minWidth':'100px','height':'auto'},style_cell_conditional=[{'if':{'column_id':'Título'},'width':'20%'},{'if':{'column_id':'Institución'},'width':'20%'}])])]),\n",
    "    html.Br(),\n",
    "    html.P(\"Para más información, visite la URL\")\n",
    "    ])\n",
    "        \n",
    "\n",
    "#aquí debería ir el callback del tipo de especies: va a limitar las opciones que aparezcan a continuación\n",
    "\n",
    "@callback(\n",
    "        Output(\"predios_barras\",\"figure\"),\n",
    "        Output(\"predios_barras_lplp\",\"figure\"),\n",
    "        Output(\"tabla_nombres\",\"data\"),\n",
    "        Output(\"tabla_nombres\",\"columns\"),\n",
    "        Output('wordcloud','src'),\n",
    "        Output('paper_año','figure'),\n",
    "        Output('mapa_paises','figure'),\n",
    "        Output(\"grafico\",\"figure\"),\n",
    "        Output(\"mapa-terrenos\", \"figure\"),\n",
    "        Input(\"entrada\",\"value\"))\n",
    "\n",
    "#Primero filtrar el JSON por especie\n",
    "\n",
    "def filtro(valor):\n",
    "\n",
    "    if valor is None:  # Si no hay selección\n",
    "        raise PreventUpdate\n",
    "    else:\n",
    "        #Filtrar por nombre/ID\n",
    "        df_especies_filtrado = df_especies[df_especies['ID'].isin(valor)]\n",
    "        nombre_cien= df_especies_filtrado['Nombre científico']   \n",
    "        nombre_com= df_especies_filtrado['Nombre común']\n",
    "        nombre_ori=df_especies_filtrado['Nombre originario']         \n",
    "        df=pd.DataFrame({'Nombre científico':nombre_cien,'Nombre común':nombre_com,'Nombre originario':nombre_ori})\n",
    "        data=df.to_dict('records')\n",
    "        columns=[{'id':c,'name':c}for c in df.columns]\n",
    "\n",
    "        #esta parte filtra el json: abstract\n",
    "        json_filtrado = [{paper['PMID']: paper['Abstract']} for paper in pubmed_data if paper['ID'] in valor]\n",
    "        fig=px.scatter(procesar_json_fil(json_filtrado),x='f rel',y='f abs',size='total',hover_data=['listas presentes'],hover_name='lemma',opacity=0.5,title=\"Presencia y Abundancia de términos\",labels={'f rel':'Presencia','f abs':'Abundancia'})\n",
    "\n",
    "        #esta parte filtra el json: solo pmids:lista\n",
    "        lista_pmids=[]\n",
    "        for paper in pubmed_data:\n",
    "            if paper['ID'] in valor:\n",
    "                lista_pmids.append(paper['PMID'])\n",
    "\n",
    "        #Supongo que aquí tiene que ir para el mapa mundi\n",
    "        # \n",
    "        \n",
    "        \n",
    "        #llamar a función paises y graficar mapa mundi\n",
    "        \n",
    "        #keywords y año\n",
    "        keywords=[]\n",
    "        año_paper=[]\n",
    "        pubmedid=[]\n",
    "        nombrecien=[]\n",
    "\n",
    "        for paper in pubmed_data:\n",
    "            if paper['ID'] in valor:\n",
    "                keywords.append(paper['Keywords'])\n",
    "                año_paper.append(paper['Date']['Year'])\n",
    "                pubmedid.append(paper['PMID'])\n",
    "                nombrecien.append(paper['Topic'])\n",
    "        wc=WordCloud(background_color='white',colormap='Greens',width=400,height=400).generate(procesar_keywords(keywords))\n",
    "        wc.to_file(\"wordcloudkw.png\")\n",
    "        encoded_image= Image.open('wordcloudkw.png')\n",
    "        \n",
    "        #gráfico papers por año\n",
    "        df_paper_año=pd.DataFrame({'PMID':pubmedid,\"Año\":año_paper,\"Nombre científico\":nombrecien})\n",
    "        df_paper_año=df_paper_año.groupby(['Nombre científico','Año'])['PMID'].count().reset_index()\n",
    "        fig_pap_año=px.bar(df_paper_año,x=\"Año\",y=\"PMID\",color='Nombre científico',labels={'PMID':'Número de Publicaciones'},title='Número de papers publicados por año',width=400,height=400)\n",
    "        fig_pap_año.update_layout(xaxis={'categoryorder':'category ascending'},margin={\"r\":10,\"t\":10,\"l\":10,\"b\":10})\n",
    "\n",
    "        fig_mapa=px.choropleth(procesar_paises(valor),locations=\"Alpha-3 code\",color=\"Recuento\",color_continuous_scale='Greens',projection='natural earth',title='Países donde se investiga',width=400,height=400)\n",
    "        fig_mapa.update_geos(showcoastlines=False,framewidth=0.3,framecolor=\"#444\")\n",
    "        fig_mapa.update_layout(coloraxis_showscale=True)\n",
    "        #fig_mapa.update_layout()\n",
    "\n",
    "\n",
    "        #filtro el dataset predios\n",
    "        df_predios_group_filtro = df_predios_group[df_predios_group['ID'].isin(valor)]\n",
    "        fig_predios=px.bar(df_predios_group_filtro,x='USO_CEFOR',y='SUP_HA',color='Nombre científico',text_auto=True,labels={'SUP_HA':'Superficie (Há)','USO_CEFOR':'Uso de suelo'},title='Superficie por uso de suelo y especie')\n",
    "        fig_predios.update_layout(xaxis={'categoryorder':'total descending'})\n",
    "\n",
    "        df_predios_group_filtro_lplp = df_predios_group_lplp[df_predios_group_lplp['ID'].isin(valor)]\n",
    "        fig_predios_lplp=px.bar(df_predios_group_filtro_lplp,x='NOMBRE',y='SUP_HA',color='Nombre científico',text_auto=True,labels={'SUP_HA':'Superficie (Há)','NOMBRE':'Predio'},title='Superficie por predio y especie')\n",
    "        fig_predios_lplp.update_layout(xaxis={'categoryorder':'total descending'})\n",
    "\n",
    "    #mapa coropletico\n",
    "\n",
    "    if not valor:\n",
    "        features_filtrados = geojson_data[\"features\"]\n",
    "    else:\n",
    "        features_filtrados = [\n",
    "            f for f in geojson_data[\"features\"]\n",
    "            if f[\"properties\"][\"ID_es\"] in valor\n",
    "        ]\n",
    "\n",
    "        for i, f in enumerate(features_filtrados):\n",
    "            f[\"id\"] = f.get(\"id\", str(i))\n",
    "\n",
    "    geojson_filtrado = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": features_filtrados\n",
    "    }\n",
    "\n",
    "    # Crear figura vacía\n",
    "    fig_2 = go.Figure()\n",
    "\n",
    "    # ➤ Capa base: límites del predio (línea negra)\n",
    "    # ➤ Capa base: límites del predio (líneas negras)\n",
    "    for feature in geojson_limite[\"features\"]:\n",
    "        if feature[\"geometry\"][\"type\"] == \"MultiPolygon\":\n",
    "            for polygon in feature[\"geometry\"][\"coordinates\"]:\n",
    "                for ring in polygon:\n",
    "                    lons, lats = zip(*ring)\n",
    "                    fig_2.add_trace(go.Scattermap(\n",
    "                        lon=lons,\n",
    "                        lat=lats,\n",
    "                        mode=\"lines\",\n",
    "                        line=dict(width=2, color=\"black\"),\n",
    "                        name=\"Límite predio\",\n",
    "                        hoverinfo=\"skip\",\n",
    "                        showlegend=False\n",
    "                    ))\n",
    "        elif feature[\"geometry\"][\"type\"] == \"Polygon\":\n",
    "            for ring in feature[\"geometry\"][\"coordinates\"]:\n",
    "                lons, lats = zip(*ring)\n",
    "                fig_2.add_trace(go.Scattermap(\n",
    "                    lon=lons,\n",
    "                    lat=lats,\n",
    "                    mode=\"lines\",\n",
    "                    line=dict(width=2, color=\"black\"),\n",
    "                    name=\"Límite predio\",\n",
    "                    hoverinfo=\"skip\",\n",
    "                    showlegend=False\n",
    "                ))\n",
    "\n",
    "    # ➤ Capa de especies: usando choropleth\n",
    "    fig_map = px.choropleth_map(\n",
    "        geojson=geojson_filtrado,\n",
    "        locations=[f[\"id\"] for f in features_filtrados],\n",
    "        color=[f[\"properties\"][\"Clasificación\"] for f in features_filtrados],\n",
    "        hover_name=[f[\"properties\"][\"Nombre científico\"] for f in features_filtrados],\n",
    "        featureidkey=\"id\",\n",
    "        zoom=13,\n",
    "        center={\"lat\": -39.74, \"lon\": -73.14},\n",
    "        #opacity=0.5\n",
    "    )\n",
    "\n",
    "    # ➤ Añadir la capa de especies sobre la figura existente\n",
    "    for trace in fig_map.data:\n",
    "        fig_2.add_trace(trace)\n",
    "\n",
    "    # Ajustar el diseño final\n",
    "    fig_2.update_layout(\n",
    "        margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0},\n",
    "        map=dict(\n",
    "            style=\"open-street-map\",\n",
    "            zoom=13,\n",
    "            center={\"lat\": -39.74, \"lon\": -73.14}\n",
    "        )\n",
    "    )        \n",
    "        \n",
    "    return fig_predios,fig_predios_lplp,data,columns,encoded_image,fig_pap_año,fig_mapa,fig,fig_2\n",
    "\n",
    "#segundo callback\n",
    "\n",
    "@callback(\n",
    "    Output('tabla','data'),\n",
    "    Output('tabla','columns'),\n",
    "    Input('grafico','clickData')\n",
    "    )\n",
    "\n",
    "def display_click_data(clickData):\n",
    "    if clickData is None:  # Si no hay selección\n",
    "        raise PreventUpdate\n",
    "    else:\n",
    "    \n",
    "       #id=[p['custDataomdata'][0] for p in selectedData['points']]\n",
    "       id=clickData['points'][0]['customdata'][0] #lista\n",
    "       r=[]\n",
    "       for item in pubmed_data:\n",
    "           if item['PMID']in id:\n",
    "               r.append(item)\n",
    "       #aquí tengo que generar el df, no puedo trabajar con isin pq tengo json\n",
    "       pmid=[]\n",
    "       titulo=[]\n",
    "       urla=[]\n",
    "       revista=[]\n",
    "       fecha=[]\n",
    "       autor=[]\n",
    "       inst=[]\n",
    "       for paper in r:\n",
    "           pmid.append(paper['PMID'])\n",
    "           titulo.append(paper['Title']) #aquí se edita el formato del título? json.dumps?\n",
    "           urla.append(paper['URL'])\n",
    "           revista.append(paper['Journal'])\n",
    "           fecha.append(paper['Date']['Month']+\"/\"+paper['Date']['Year'])\n",
    "           autor.append(paper['Authors'][0]['Name']+\" \"+paper['Authors'][0]['Lastname'])\n",
    "           inst.append(\"\".join(paper['Authors'][0]['Affiliations']))\n",
    "\n",
    "           df=pd.DataFrame({'PMID':pmid,'Título':titulo,'1ª autor':autor,'Institución':inst,'URL':urla,'Revista':revista,'Año':fecha})#creo que no es necesario? tal vez para hacer una tabla\n",
    "\n",
    "           data=df.to_dict('records')\n",
    "           columns=[{'id':c,'name':c}for c in df.columns]\n",
    "\n",
    "                  \n",
    "    return data,columns\n",
    "    \n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    app.run_server(port=8053,use_reloader=False,debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
